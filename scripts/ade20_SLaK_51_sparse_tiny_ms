#!/bin/bash
#SBATCH --job-name=ADE20_slak_tiny_160k_layer_wise_ms4imaspergpu
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=4
#SBATCH --gpus=4
#SBATCH -t 4-00:00:00
#SBATCH --exclusive
#SBATCH --cpus-per-task=72
#SBATCH -o ADE20_slak_tiny_160k_layer_wise_ms_4imaspergpu.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate LoRA

#module purge
#module load 2021
#module load CUDA/11.3.1
#module load PyTorch/1.10.0-foss-2021a-CUDA-11.3.1


 bash tools/dist_train.sh  configs/SLaK/upernet_slak_tiny_512_160k_ade20k_ms.py 4   \
  --work-dir /projects/0/prjste21060/projects/Segmentation/ADE20_slak_tiny_160_lw_ms_4imaspergpu/  --auto-resume  --seed 0 --deterministic


source deactivate
