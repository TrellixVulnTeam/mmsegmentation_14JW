#!/bin/bash
#SBATCH --job-name=ADE20_slak_tiny_80k_61_layer_wise
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=4
#SBATCH --gpus=4
#SBATCH -t 3-12:00:00
#SBATCH --exclusive
#SBATCH --cpus-per-task=72
#SBATCH -o ADE20_slak_tiny_80k_61_layer_wise.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate LoRA

#module purge
#module load 2021
#module load CUDA/11.3.1
#module load PyTorch/1.10.0-foss-2021a-CUDA-11.3.1


 bash tools/dist_train.sh  configs/SLaK/upernet_slak_tiny_512_80k_ade20k_ss_61.py 4   \
  --work-dir /projects/0/prjste21060/projects/Segmentation/ADE20_slak_tiny_80_31_lw/  --auto-resume  --seed 0 --deterministic


source deactivate
